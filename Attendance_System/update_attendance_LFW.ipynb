{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import imageio\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import math\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import sys\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attendance\n",
    "\n",
    "def label_test_images(cascade,scaleFactor,minNeighbors,dir_list,pred,names,data_dir,save_dir):\n",
    "  for i in range(np.array(dir_list).size):\n",
    "    im = np.array(Image.open(data_dir+'/'+dir_list[i]))\n",
    "    faces_rect = cascade.detectMultiScale(im, scaleFactor=scaleFactor, minNeighbors=minNeighbors)    \n",
    "    name = names[pred[i]]\n",
    "    for (x, y, _w, _h) in [faces_rect[np.argmax(faces_rect.T[-1])]]:\n",
    "      cv2.rectangle(im, (x, y), (x+_w, y+_h), (0, 255, 0), 2)\n",
    "      cv2.putText(im, name, (x + 6, y+_h - 6), cv2.FONT_HERSHEY_DUPLEX, 0.5, (255, 255, 255), 1)\n",
    "      imageio.imwrite(save_dir+'/'+dir_list[i], im)\n",
    "\n",
    "def update_attendance(pred,names,save_dir,date):\n",
    "  data = np.unique(pred)\n",
    "  enc = OneHotEncoder()\n",
    "  data = np.sum(enc.fit_transform(np.expand_dims(np.append(data,np.arange(n_persons)),1)).toarray()[0:data.size],axis=0)\n",
    "  #date=str(sys.argv[1]) #'25.05.2020'\n",
    "  if(os.path.exists(save_dir+'/Attendance.xlsx')):\n",
    "    df = pd.read_excel(save_dir+'/Attendance.xlsx', sheet_name='Students')\n",
    "  else:\n",
    "    df = pd.DataFrame(names,columns=['Name'])\n",
    "\n",
    "  df[date] = data  \n",
    "  df.to_excel(save_dir+\"/Attendance.xlsx\", sheet_name='Students',index=False)  \n",
    "\n",
    "def hist_equalizer(im):\n",
    "  img_yuv = cv2.cvtColor(np.array(im), cv2.COLOR_BGR2YUV)\n",
    "  # equalize the histogram of the Y channel\n",
    "  img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
    "  # convert the YUV image back to RGB format\n",
    "  im = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2RGB)\n",
    "  return im\n",
    "\n",
    "def get_aligned_img(img, sF=1.05, mN=1): # input PIL Image\n",
    "  img = np.array(img)\n",
    "  img_raw = img.copy() \n",
    "  eyes = eye_cascade.detectMultiScale(img,sF,mN)\n",
    "  gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "  eye_1 = (0,0,0,0)\n",
    "  eye_2 = (0,0,0,0)\n",
    "  eyes = np.array(eyes)\n",
    "  possible_eyes = []\n",
    "  for i in range(len(eyes)):\n",
    "    if(quadrant_checker(eyes[i][1])):\n",
    "      possible_eyes.append(i)\n",
    "  eyes = eyes[possible_eyes]\n",
    "  if(len(eyes) == 0):\n",
    "    return cv2.cvtColor(img_raw, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "  left_eye = eyes[np.argmin(eyes.T[0])]\n",
    "  right_eye = eyes[np.argmax(eyes.T[0])]\n",
    "  cv2.rectangle(img,(left_eye[0], left_eye[1]),(left_eye[0]+left_eye[2], left_eye[1]+left_eye[3]), 1)\n",
    "  cv2.rectangle(img,(right_eye[0], right_eye[1]),(right_eye[0]+right_eye[2], right_eye[1]+right_eye[3]), 1)\n",
    "  left_eye_center = (int(left_eye[0] + (left_eye[2] / 2)), int(left_eye[1] + (left_eye[3] / 2)))\n",
    "  left_eye_x = left_eye_center[0]; left_eye_y = left_eye_center[1]\n",
    "\n",
    "  right_eye_center = (int(right_eye[0] + (right_eye[2]/2)), int(right_eye[1] + (right_eye[3]/2)))\n",
    "  right_eye_x = right_eye_center[0]; right_eye_y = right_eye_center[1]\n",
    "\n",
    "  if(len(left_eye) == 0 or len(right_eye) == 0):\n",
    "    return cv2.cvtColor(img_raw, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "  cv2.circle(img, left_eye_center, 1, (255, 0, 0) , 1)\n",
    "  cv2.circle(img, right_eye_center, 1, (255, 0, 0) , 1)\n",
    "  cv2.line(img,right_eye_center, left_eye_center,(67,67,67),1)\n",
    "  if(left_eye_y > right_eye_y):\n",
    "    point_3rd = (right_eye_x, left_eye_y)\n",
    "    direction = -1 #rotate same direction to clock\n",
    "\n",
    "  else:\n",
    "    point_3rd = (left_eye_x, right_eye_y)\n",
    "    direction = 1 #rotate inverse direction of clock\n",
    "\n",
    "  cv2.line(img,right_eye_center, left_eye_center,(67,67,67),1)\n",
    "  cv2.line(img,left_eye_center, point_3rd,(67,67,67),1)\n",
    "  cv2.line(img,right_eye_center, point_3rd,(67,67,67),1)\n",
    "  \n",
    "  a = euclidean_distance(left_eye_center, point_3rd)\n",
    "  b = euclidean_distance(right_eye_center, left_eye_center)\n",
    "  c = euclidean_distance(right_eye_center, point_3rd)\n",
    "\n",
    "  if(b == 0 or c == 0):\n",
    "    #new_img = Image.fromarray(img_raw)\n",
    "    gray_new_img = cv2.cvtColor(img_raw, cv2.COLOR_RGB2GRAY)\n",
    "    #return gray_new_img\n",
    "\n",
    "  else:\n",
    "    cos_a = (b*b + c*c - a*a)/(2*b*c)\n",
    "    angle = np.arccos(cos_a)\n",
    "    angle = (angle * 180) / math.pi\n",
    "\n",
    "    if direction == -1:\n",
    "      angle = 90 - angle  \n",
    "\n",
    "    new_img = Image.fromarray(img_raw)\n",
    "    new_img = np.array(new_img.rotate(direction * angle))\n",
    "    gray_new_img = cv2.cvtColor(new_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    for i in range(gray_new_img.shape[0]):\n",
    "      if(gray_new_img[i][0] == 0):\n",
    "        ctr = 0\n",
    "        while(np.allclose(gray_new_img[i][ctr],0)):\n",
    "          ctr += 1\n",
    "        gray_new_img[i][0:ctr] = np.ones(gray_new_img[i][0:ctr].size)*gray_new_img[i][ctr]\n",
    "      if(gray_new_img[i][-1] == 0):\n",
    "        ctr = 0\n",
    "        while(np.allclose(gray_new_img[i][-1-ctr],0)):\n",
    "          ctr += 1\n",
    "        gray_new_img[i][gray_new_img.shape[1]-ctr:] = np.ones(gray_new_img[i][gray_new_img.shape[1]-ctr:].size)*gray_new_img[i][-1-ctr]\n",
    "\n",
    "  return gray_new_img\n",
    "\n",
    "def quadrant_checker(y):\n",
    "  if(y<64 and y>0):\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def euclideanDistance(x,y):\n",
    "  distance = 0\n",
    "  for i in range(x.size):\n",
    "    distance += (x[i] - y[i])**2\n",
    "  return np.sqrt(distance)\n",
    "\n",
    "def euclidean_distance(a, b):\n",
    "  x1 = a[0]; y1 = a[1]\n",
    "  x2 = b[0]; y2 = b[1]\n",
    "  return math.sqrt(((x2 - x1) * (x2 - x1)) + ((y2 - y1) * (y2 - y1)))\n",
    "\n",
    "def first_comes_first(arr,x):\n",
    "    arr[1:] = arr[0:-1]\n",
    "    arr[0] = x\n",
    "    return arr\n",
    "\n",
    "def kNN(test_data,train_data,train_class,k):\n",
    "  test_pred = np.zeros(test_data.shape[0])\n",
    "  for i in range(test_data.shape[0]):\n",
    "    dist_arr = np.asarray(np.zeros(k))\n",
    "    nearest = np.asarray(np.zeros(k))\n",
    "    ret_arr = np.array([])\n",
    "    for j in range(k):\n",
    "      dist_arr[j] = euclideanDistance(train_data[j],test_data[i])\n",
    "      nearest[j]=j\n",
    "\n",
    "    for j in range(train_data.shape[0]):\n",
    "      temp_dist = euclideanDistance(test_data[i],train_data[j])\n",
    "      if(temp_dist <= np.amin(dist_arr)):\n",
    "        dist_arr = first_comes_first(dist_arr,temp_dist)\n",
    "        nearest = first_comes_first(nearest,j)\n",
    "\n",
    "    for j in (nearest):\n",
    "      ret_arr = np.append(ret_arr,train_class[int(j)])\n",
    "    ret_arr = np.array([int(q) for q in ret_arr])\n",
    "    test_pred[i] = np.argmax(np.bincount(ret_arr))\n",
    "\n",
    "  return test_pred\n",
    "\n",
    "def run_SVM(X_train_scaled,X_test_scaled,Y_train,cv=5,kernel='rbf',gamma=0.001,C=10):\n",
    "#  params_grid = [{'kernel': [kernel], 'gamma': [gamma],'C': [C]}]\n",
    "  svm_model = SVC(kernel=kernel,C=C,gamma=gamma) #GridSearchCV(SVC(), params_grid, cv=cv)\n",
    "  svm_model.fit(X_train_scaled, Y_train)\n",
    "  Y_pred = svm_model.predict(X_test_scaled)\n",
    "  \n",
    "  return Y_pred, svm_model\n",
    "\n",
    "\n",
    "def accuracy(yhat,Y_test):\n",
    "  ctr = 0.0\n",
    "  for i in range(Y_test.size):  \n",
    "    if(yhat[i] == Y_test[i]):\n",
    "      ctr += 1.0\n",
    "\n",
    "  return ((ctr/Y_test.size)*100)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simply define a silu function\n",
    "def hakuna_matata(x,x0 = 0,a=1):\n",
    "  return 2/(1+torch.exp(-a*(x-x0))) - 1 # use torch.sigmoid to make sure that we created the most efficient implemetation based on builtin PyTorch functions\n",
    "\n",
    "# create a class wrapper from PyTorch nn.Module, so\n",
    "# the function now can be easily used in models\n",
    "class Hakuna_Matata(nn.Module):\n",
    "  def __init__(self,x0=0,a=1):\n",
    "    super().__init__() # init the base class\n",
    "    self.a = a\n",
    "    self.x0 = x0\n",
    "\n",
    "  def forward(self, ip):\n",
    "    return hakuna_matata(ip,self.x0,self.a) # simply apply already implemented SiLU\n",
    "\n",
    "class RegularizedLinear(nn.Linear):\n",
    "    def __init__(self, *args, ar_weight=1e-3, l1_weight=1e-3, l2_weight=2, **kwargs):\n",
    "        super(RegularizedLinear, self).__init__(*args, **kwargs)\n",
    "        #self.ar_weight = ar_weight\n",
    "        #self.l1_weight = l1_weight\n",
    "        self.l2_weight = l2_weight\n",
    "        self._losses = {}\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = super(RegularizedLinear, self).forward(input)\n",
    "        #self._losses['activity_regularization'] = (output * output).sum() * self.ar_weight\n",
    "        #self._losses['l1_weight_regularization'] = torch.abs(self.weight).sum() * self.l1_weight\n",
    "        self._losses['l2_weight_regularization'] = torch.abs(torch.mul(self.weight,self.weight)).sum() * self.l2_weight\n",
    "        return output\n",
    "\n",
    "class FFNNetwork_Regularized(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    torch.manual_seed(0)\n",
    "    self.scale_factor = 0.75\n",
    "    self.shift_param = +1.75\n",
    "    self.net = nn.Sequential(\n",
    "        #nn.Dropout(0.2),\n",
    "        RegularizedLinear(n_components,2048), \n",
    "        nn.BatchNorm1d(2048),\n",
    "        nn.Dropout(0.1),\n",
    "        Hakuna_Matata(self.shift_param,self.scale_factor),\n",
    "        #nn.Tanh(),\n",
    "        #RegularizedLinear(4096,2048), \n",
    "        #nn.BatchNorm1d(2048),\n",
    "        #Hakuna_Matata(self.shift_param,self.scale_factor),\n",
    "        RegularizedLinear(2048,1024), \n",
    "        nn.BatchNorm1d(1024),\n",
    "        Hakuna_Matata(self.shift_param,self.scale_factor),\n",
    "        RegularizedLinear(1024,512), \n",
    "        nn.BatchNorm1d(512),\n",
    "#        nn.Dropout(0.2),\n",
    "        Hakuna_Matata(self.shift_param,self.scale_factor),\n",
    "        #nn.Tanh(),\n",
    "        RegularizedLinear(512, 250), \n",
    "        nn.BatchNorm1d(250),\n",
    "        #nn.Dropout(0.04),\n",
    "        Hakuna_Matata(self.shift_param,self.scale_factor),\n",
    "        #nn.Tanh(),   \n",
    "#        RegularizedLinear(250, 512), \n",
    "#        nn.BatchNorm1d(512),\n",
    "#        nn.Tanh(),\n",
    "#        nn.Dropout(0.1),\n",
    "        #Hakuna_Matata(-1,1),\n",
    "#        RegularizedLinear(512,512),\n",
    "#        nn.BatchNorm1d(512),\n",
    "#        nn.Tanh(),\n",
    "#        RegularizedLinear(512,512),\n",
    "#        nn.BatchNorm1d(512),\n",
    "#        nn.Tanh(),\n",
    "        RegularizedLinear(250,names.size),\n",
    "        nn.BatchNorm1d(names.size),\n",
    "#        nn.Dropout(0.1),\n",
    "        Hakuna_Matata(self.shift_param,self.scale_factor),\n",
    "        #nn.Tanh(),   \n",
    "        nn.Softmax()\n",
    "    )\n",
    "\n",
    "  def forward(self, X):\n",
    "    return self.net(X)\n",
    "\n",
    "  def softmax(self,x):\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x))\n",
    "\n",
    "  def cross_entropy(self,pred,label):\n",
    "    yl=torch.mul(pred,label)\n",
    "    yl=yl[yl!=0]\n",
    "    yl=-torch.log(yl)\n",
    "    yl=torch.mean(yl)\n",
    "    return yl\n",
    "\n",
    "  def accuracy(self,y_hat, y):\n",
    "    pred = torch.argmax(y_hat, dim=1)\n",
    "    return (pred == y).float().mean()\n",
    "\n",
    "  def predict(self, X):\n",
    "    Y_pred = self.forward(X)\n",
    "    return np.array(Y_pred).squeeze()\n",
    "  \n",
    "  def accuracy_n(self,y_hat, y,topk=(1,)):\n",
    "    maxk = max(topk)\n",
    "    batch_size = y.size(0)\n",
    "\n",
    "    _, pred = y_hat.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(y.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "  \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/media/kiran/New Volume/SEM_6/Machine Learning for Signal Processing/Course Project/FINAL/SC17B106_SC17B150\"\n",
    "folder = \"/LFW_SubDataSet\"\n",
    "data_folder = \"/Test_images\"\n",
    "save_folder = \"/Labelled_images\"\n",
    "M = np.loadtxt(path+folder+'/M_LFW.txt')\n",
    "C = np.loadtxt(path+folder+'/C_LFW.txt')\n",
    "X_train = np.loadtxt(path+folder+'/X_train_LFW.txt')\n",
    "Y_train = np.loadtxt(path+folder+'/Y_train_LFW.txt')\n",
    "scaler = StandardScaler()#load(open(path+'/new/scaler.pkl', 'rb'))\n",
    "weightage = np.array([0.3,0.3,0.4])#np.loadtxt(path+'/new/weightage.txt')\n",
    "n_components = C.shape[0]\n",
    "\n",
    "a = np.array([])\n",
    "with open(path+folder+\"/new.txt\",'r') as f:\n",
    "  for line in f:\n",
    "    if(len(line) != 0):\n",
    "      if(a.size == 0):\n",
    "        a = np.array(line.split())\n",
    "      else:\n",
    "        a = np.row_stack((a,line.split()))\n",
    "\n",
    "names = []\n",
    "names = a.T[0]\n",
    "attendance = np.zeros(names.size)\n",
    "del a\n",
    "\n",
    "n_persons = names.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Testing Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_cascade = cv2.CascadeClassifier(path+folder+'/haarcascade_eye.xml')\n",
    "haar_cascade_face = cv2.CascadeClassifier(path+folder+'/haarcascade_frontalface_alt.xml')\n",
    "scaleFactor = 1.1\n",
    "minNeighbors = 1\n",
    "form = '.jpg'\n",
    "dir_list = os.listdir(path+folder+data_folder) \n",
    "w=64\n",
    "h=64\n",
    "\n",
    "#Y_test = np.array([])\n",
    "X_test = np.array([])\n",
    "crop_dims=[14,62,8,54]\n",
    "sF = 1.05\n",
    "mN = 1\n",
    "test_images = np.array([])\n",
    "for img in os.listdir(path+folder+data_folder):\n",
    "  #Y_test = np.append(Y_test,np.where(names == img[:-9]))\n",
    "  im = np.array(Image.open(path+folder+data_folder+'/'+img))\n",
    "  faces_rect = haar_cascade_face.detectMultiScale(im, scaleFactor=1.1, minNeighbors=1)    \n",
    "  for (x, y, _w, _h) in [faces_rect[np.argmax(faces_rect.T[-1])]]:\n",
    "    crop_im = im[y:y+_h, x:x+_w]\n",
    "    crop_im = cv2.resize(crop_im, (w,h), interpolation = cv2.INTER_AREA)\n",
    "    crop_im = crop_im[crop_dims[0]:crop_dims[1],crop_dims[2]:crop_dims[3]]\n",
    "    crop_im = cv2.resize(crop_im, (w,h), interpolation = cv2.INTER_AREA)\n",
    "    crop_im = hist_equalizer(crop_im)\n",
    "    crop_im = get_aligned_img(crop_im,sF,mN)\n",
    "    temp = np.array(crop_im)        \n",
    "    temp = cv2.equalizeHist(temp).ravel()\n",
    "    if(test_images.size == 0):\n",
    "      test_images = temp\n",
    "    else:\n",
    "      test_images = np.row_stack((test_images,temp))\n",
    "    temp = np.matmul((temp-M),C.T)\n",
    "    if(X_test.size == 0):\n",
    "      X_test = temp\n",
    "    else:\n",
    "      X_test = np.row_stack((X_test,temp)) \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_kNN = kNN(X_test,X_train,Y_train,k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_pred_SVM, SVM_model = run_SVM(X_train_scaled,X_test_scaled,Y_train,cv=5,kernel='rbf',gamma=0.001,C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kiran/.local/lib/python3.6/site-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    }
   ],
   "source": [
    "FFNN_model = FFNNetwork_Regularized()\n",
    "FFNN_model.load_state_dict(torch.load(path+folder+\"/CLASS_FFNNetwork_LFW_91.txt\",  map_location=lambda storage, loc: storage)) \n",
    "FFNN_model.eval()\n",
    "X_test_scaled = torch.tensor(X_test_scaled).float()\n",
    "with torch.no_grad():\n",
    "  pred = FFNN_model.predict(X_test_scaled)\n",
    "\n",
    "Y_pred_FFNN = np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marking Attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "Y_OH_kNN = enc.fit_transform(np.expand_dims(np.append(Y_pred_kNN,np.arange(n_persons)),1)).toarray()[0:Y_pred_kNN.size]\n",
    "Y_OH_SVM = enc.fit_transform(np.expand_dims(np.append(Y_pred_SVM,np.arange(n_persons)),1)).toarray()[0:Y_pred_SVM.size]\n",
    "Y_OH_FFNN = enc.fit_transform(np.expand_dims(np.append(Y_pred_FFNN,np.arange(n_persons)),1)).toarray()[0:Y_pred_FFNN.size]\n",
    "Y_pred_ensemble = np.argmax(weightage[0]*Y_OH_kNN + weightage[1]*Y_OH_SVM + weightage[2]*Y_OH_FFNN , axis=1)\n",
    "\n",
    "dir_list = os.listdir(path+folder+data_folder) \n",
    "label_test_images(haar_cascade_face,1.1,1,dir_list,Y_pred_ensemble,names,path+folder+data_folder,path+folder+save_folder)\n",
    "update_attendance(Y_pred_ensemble,names,path+folder+save_folder,date='25.05.2020')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
